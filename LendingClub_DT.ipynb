{"cells":[{"cell_type":"code","source":["# This note books is to predict whether loan will be charged off or not; it's based on  Lending club Data.. \n# Data can be downloaded from here: https://www.kaggle.com/wendykan/lending-club-loan-data/data\n# DecisionTreeClassifier is used to predict the bad loan\n# For Transformation - One Hot Encoding and Vector Transformation is applied\n\n# These files contain complete loan data for all loans issued through the 2007-2015, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. The file containing loan data through the \"present\" contains complete loan data for all loans issued through the previous completed calendar quarter. Additional features include credit scores, number of finance inquiries, address including zip codes, and state, and collections among others. The file is a matrix of about 890 thousand observations and 75 variables. A data dictionary is provided in a separate file. \n\n## To check the accuracy of prediction BinaryClassificationEvaluator is used\n\n1. Linear Regression\n2. Logistic Regression\n3. Linear Discriminant Analysis\n4. Classification and Regression Trees\n5. Naive Bayes\n6. K-Nearest Neighbors\n7. Learning Vector Quantization\n8. Support Vector Machines\n9. Bagging and Random Forest\n10. Boosting and AdaBoost"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Load the Lending club data\n\ndata = spark.read.format(\"com.databricks.spark.csv\")\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"/FileStore/tables/LendingClub_loan_data.csv\")\ndata.cache()  # Cache data for faster reuse\ndf = data.sample(True,  0.15).limit(int(0.1 * data.count()))\ndf = df.select(df.id, df.member_id, df.loan_amnt, df.funded_amnt, df.funded_amnt_inv, df.term,  df.int_rate, \\\n          df.installment, df.grade, df.sub_grade, df.emp_title, df.emp_length, df.home_ownership, \\\n          df.annual_inc.cast(\"float\"), df. verification_status, df.issue_d, df.loan_status, df.pymnt_plan, \\\n          df.url, df.desc, df.purpose, df.title, df.zip_code, df.addr_state, df.dti.cast(\"float\"), \\\n          df.delinq_2yrs.cast(\"float\"),  df.earliest_cr_line, df.inq_last_6mths.cast(\"float\"), \\\n          df.mths_since_last_delinq.cast(\"int\"), df.mths_since_last_record.cast(\"int\"), \\\n          df.open_acc.cast(\"float\"), df.pub_rec.cast(\"float\") , df.revol_bal.cast(\"float\"), \\\n          df.revol_util.cast(\"float\"), df.total_acc.cast(\"float\"), df.initial_list_status, \n          df.out_prncp.cast(\"float\"), df.out_prncp_inv.cast(\"float\"), \\\n          df.total_pymnt.cast(\"float\"), df.total_pymnt_inv.cast(\"float\"), \\\n          df.total_rec_prncp.cast(\"float\"), df.total_rec_int.cast(\"float\"),\\\n          df.total_rec_late_fee.cast(\"float\"), df.recoveries.cast(\"float\"), \\\n          df.collection_recovery_fee.cast(\"float\"), df.last_pymnt_d, df.last_pymnt_amnt.cast(\"float\"), \\\n          df.next_pymnt_d, df.last_credit_pull_d, df.collections_12_mths_ex_med.cast(\"float\"), \\\n          df.mths_since_last_major_derog.cast(\"float\"),  df.policy_code.cast(\"float\"), df.application_type,  \\\n          df.annual_inc_joint.cast(\"float\") , df.dti_joint.cast(\"float\"), \\\n          df.verification_status_joint, df.acc_now_delinq.cast(\"float\"), \\\n          df.tot_coll_amt.cast(\"float\"), df.tot_cur_bal.cast(\"float\"), \\\n          df.open_acc_6m.cast(\"float\"), df.open_il_6m.cast(\"float\"), \\\n          df.open_il_12m.cast(\"float\"), df.open_il_24m.cast(\"float\"), \\\n          df.mths_since_rcnt_il.cast(\"float\"), df.total_bal_il.cast(\"float\"),\\\n          df.il_util.cast(\"float\"), df.open_rv_12m.cast(\"float\"), \\\n          df.open_rv_24m.cast(\"float\"), df.max_bal_bc.cast(\"float\"), \\\n          df.all_util.cast(\"float\"), df.total_rev_hi_lim.cast(\"float\"), \\\n          df.inq_fi.cast(\"float\"), df.total_cu_tl.cast(\"float\"), df.inq_last_12m.cast(\"float\"))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["## Drop highly correlated columns\nprint(df.count())\ndrop_list = [ \"id\", \"member_id\",  \"url\",  \"purpose\",  \"title\",  \"zip_code\",  \"emp_title\",  \"earliest_cr_line\",  \"term\",  \"sub_grade\", \"last_pymnt_d\",  \"next_pymnt_d\",  \"last_credit_pull_d\",  \"issue_d\", \"desc\",  \"addr_state\", \"pymnt_plan\"]\n\ndf = df.select([column for column in df.columns if column not in drop_list])\n\n  \ncols = df.columns\ndf = df.fillna(-1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">88737\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["###One-Hot Encoding\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\ncategorical_columns = [\"grade\", \"emp_length\", \"home_ownership\", \"verification_status\",  \"initial_list_status\", \"application_type\", \"verification_status_joint\"]\n\n\nstages = [] # stages in our Pipeline\nfor categoricalCol in categorical_columns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\",  handleInvalid = \"skip\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Convert label into label indices using the StringIndexer\nlabel_stringIdx = StringIndexer(inputCol = \"loan_status\", outputCol = \"label\", handleInvalid = \"skip\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Transform all features into a vector using VectorAssembler\nnumericCols = [\"loan_amnt\", \"funded_amnt\", \"funded_amnt_inv\", \"int_rate\",\n       \"installment\", \"annual_inc\", \"dti\", \"delinq_2yrs\", \"inq_last_6mths\",\n       \"mths_since_last_delinq\", \"mths_since_last_record\", \"open_acc\",\n       \"pub_rec\", \"revol_bal\", \"revol_util\", \"total_acc\", \"out_prncp\",\n       \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\",\n       \"total_rec_int\", \"total_rec_late_fee\", \"recoveries\",\n       \"collection_recovery_fee\", \"last_pymnt_amnt\",\n       \"collections_12_mths_ex_med\", \"mths_since_last_major_derog\",\n       \"policy_code\", \"annual_inc_joint\", \"dti_joint\", \"acc_now_delinq\",\n       \"tot_coll_amt\", \"tot_cur_bal\", \"open_acc_6m\", \"open_il_6m\",\n       \"open_il_12m\", \"open_il_24m\", \"mths_since_rcnt_il\", \"total_bal_il\",\n       \"il_util\", \"open_rv_12m\", \"open_rv_24m\", \"max_bal_bc\", \"all_util\",\n       \"total_rev_hi_lim\", \"inq_fi\", \"total_cu_tl\", \"inq_last_12m\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categorical_columns)\nassemblerInputs = list(assemblerInputs) + numericCols\n\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nprint(assembler)\nstages += [assembler]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">VectorAssembler_4a89bee5ab8e6578ca58\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(df)\nprint(pipelineModel)\ndataset = pipelineModel.transform(df)\n\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + cols\ndataset = dataset.select(selectedcols)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">88737\nPipelineModel_4be59db815324e121354\n106\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["print(df.count())\nprint(dataset.count())\n### Randomly split data into training and test sets. set seed for reproducibility\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint( trainingData.count())\nprint (testData.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">88737\n106\n72\n34\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\n# Train model with Training Data\ndtModel = dt.fit(trainingData) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["print( \"numNodes = \", dtModel.numNodes)\nprint (\"depth = \", dtModel.depth)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">numNodes =  9\ndepth =  3\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = dtModel.transform(testData)\npredictions.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- label: double (nullable = false)\n-- features: vector (nullable = true)\n-- loan_amnt: double (nullable = false)\n-- funded_amnt: double (nullable = false)\n-- funded_amnt_inv: double (nullable = false)\n-- int_rate: double (nullable = false)\n-- installment: double (nullable = false)\n-- grade: string (nullable = true)\n-- emp_length: string (nullable = true)\n-- home_ownership: string (nullable = true)\n-- annual_inc: float (nullable = false)\n-- verification_status: string (nullable = true)\n-- loan_status: string (nullable = true)\n-- dti: float (nullable = false)\n-- delinq_2yrs: float (nullable = false)\n-- inq_last_6mths: float (nullable = false)\n-- mths_since_last_delinq: integer (nullable = true)\n-- mths_since_last_record: integer (nullable = true)\n-- open_acc: float (nullable = false)\n-- pub_rec: float (nullable = false)\n-- revol_bal: float (nullable = false)\n-- revol_util: float (nullable = false)\n-- total_acc: float (nullable = false)\n-- initial_list_status: string (nullable = true)\n-- out_prncp: float (nullable = false)\n-- out_prncp_inv: float (nullable = false)\n-- total_pymnt: float (nullable = false)\n-- total_pymnt_inv: float (nullable = false)\n-- total_rec_prncp: float (nullable = false)\n-- total_rec_int: float (nullable = false)\n-- total_rec_late_fee: float (nullable = false)\n-- recoveries: float (nullable = false)\n-- collection_recovery_fee: float (nullable = false)\n-- last_pymnt_amnt: float (nullable = false)\n-- collections_12_mths_ex_med: float (nullable = false)\n-- mths_since_last_major_derog: float (nullable = false)\n-- policy_code: float (nullable = false)\n-- application_type: string (nullable = true)\n-- annual_inc_joint: float (nullable = false)\n-- dti_joint: float (nullable = false)\n-- verification_status_joint: string (nullable = true)\n-- acc_now_delinq: float (nullable = false)\n-- tot_coll_amt: float (nullable = false)\n-- tot_cur_bal: float (nullable = false)\n-- open_acc_6m: float (nullable = false)\n-- open_il_6m: float (nullable = false)\n-- open_il_12m: float (nullable = false)\n-- open_il_24m: float (nullable = false)\n-- mths_since_rcnt_il: float (nullable = false)\n-- total_bal_il: float (nullable = false)\n-- il_util: float (nullable = false)\n-- open_rv_12m: float (nullable = false)\n-- open_rv_24m: float (nullable = false)\n-- max_bal_bc: float (nullable = false)\n-- all_util: float (nullable = false)\n-- total_rev_hi_lim: float (nullable = false)\n-- inq_fi: float (nullable = false)\n-- total_cu_tl: float (nullable = false)\n-- inq_last_12m: float (nullable = false)\n-- rawPrediction: vector (nullable = true)\n-- probability: vector (nullable = true)\n-- prediction: double (nullable = false)\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\naccuracyDt = evaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["print(\"Test Error = %g \" % (1.0 - accuracyDt))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Error = 0.2 \n</div>"]}}],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"LendingClub_DT","notebookId":771670659737928},"nbformat":4,"nbformat_minor":0}
