{"cells":[{"cell_type":"code","source":["# Goal is to predict the House Price in King County, USA \n# Dataset can be obtained from: https://www.kaggle.com/harlfoxem/housesalesprediction\n# Linear Regression is used to predict the house price\n\n# Model performance is evaluated using RMSE and R-Squared; Different Regression is used to fit the model. \n# Some of the regression techniques applied  were Ridge Regression and Lasso Regression. \n\n# Steps in Modelling:\n# 1. Clean the data/ check for null values\n# 2. Transformation: One Hot Encoding  for Categorical columns,  Vector Assembles for Features\n# 3. Fit the model into Linear Regression \n# 4. Cross validate the model for best fit.\n# 5. Compare the Performance between LinearRegression, Ridge Regression and Lasso Regression\n\n#Which parts this example conver ? delete not applicables\n#1. Linear Regression, Lasso Regression, Ridge Regression\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\n# Read the csv file and create spark Dataframe\nhousing_df = sqlContext.read.format(\"com.databricks.spark.csv\")       \\\n        .options(delimiter=',', header = True, inferSchema = True)  \\\n        .load('/FileStore/tables/kc_house_data.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Show only Top 4 results\nhousing_df.show(4)\n# Cache the dataframe\nhousing_df.cache()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+---------------+------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n        id|           date| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|    lat|    long|sqft_living15|sqft_lot15|\n+----------+---------------+------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n7129300520|20141013T000000|221900|       3|      1.0|       1180|    5650|   1.0|         0|   0|        3|    7|      1180|            0|    1955|           0|  98178|47.5112|-122.257|         1340|      5650|\n6414100192|20141209T000000|538000|       3|     2.25|       2570|    7242|   2.0|         0|   0|        3|    7|      2170|          400|    1951|        1991|  98125| 47.721|-122.319|         1690|      7639|\n5631500400|20150225T000000|180000|       2|      1.0|        770|   10000|   1.0|         0|   0|        3|    6|       770|            0|    1933|           0|  98028|47.7379|-122.233|         2720|      8062|\n2487200875|20141209T000000|604000|       4|      3.0|       1960|    5000|   1.0|         0|   0|        5|    7|      1050|          910|    1965|           0|  98136|47.5208|-122.393|         1360|      5000|\n+----------+---------------+------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\nonly showing top 4 rows\n\n<span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>DataFrame[id: bigint, date: string, price: decimal(7,0), bedrooms: int, bathrooms: double, sqft_living: int, sqft_lot: int, floors: double, waterfront: int, view: int, condition: int, grade: int, sqft_above: int, sqft_basement: int, yr_built: int, yr_renovated: int, zipcode: int, lat: double, long: double, sqft_living15: int, sqft_lot15: int]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["#  Get the count of records\nhousing_df.count()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>21613\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["housing_df.describe(\"price\", \"sqft_living\").show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------------------+------------------+\nsummary|             price|       sqft_living|\n+-------+------------------+------------------+\n  count|             21613|             21613|\n   mean|       540088.1418|2079.8997362698374|\n stddev|367127.19648270035| 918.4408970468096|\n    min|             75000|               290|\n    max|           7700000|             13540|\n+-------+------------------+------------------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Find the correlation between house price and sqft_living\ncolumn_labels = ['price','sqft_living', 'sqft_lot', 'bedrooms','bathrooms', \\\n         'floors', 'sqft_above', 'sqft_basement','yr_built','yr_renovated', \\\n        'sqft_living15', 'sqft_lot15']\nhousing_df.stat.corr( 'price', 'sqft_living' )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>0.7020350546118005\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["import numpy as np\nfrom pyspark.mllib.stat import Statistics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# find which features highly correlated with price One can use many methoods to fidn co relations between the columns \ncolumn_corr = Statistics.corr(housing_df.rdd.map(lambda x:\n                         np.array([x['price'],\n                                   x['sqft_living'],\n                                   x['sqft_lot'],\n                                   x['bedrooms'],\n                                   x['bathrooms'],\n                                   x['floors'],\n                                   x['sqft_above'],\n                                   x['sqft_basement'],\n                                   x['yr_built'],\n                                   x['yr_renovated'],\n                                   x['sqft_living15'],\n                                   x['sqft_lot15']\n                                  ])), method='pearson')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# check for null values in data\nfrom pyspark.sql.functions import isnull\n\n# Drop any rows (not columns) where Data value is Any \nhouse_df_clean = housing_df.na.drop( how = 'any' )\n\nhouse_df_clean.count() == housing_df.count()\n# if both the records are same then no null values"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Feature transformation\n## if a variable is skewed, it can be log transformed to make it more normal. Also, derive features from existing features, which can explain or predict the response variable. Price is highly  skewed; hence apply log for it.\nfrom pyspark.sql.functions import col, log\nhousing_df = housing_df.withColumn( 'log_price', log('price') )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["housing_df = housing_df.withColumn( 'log_sqft_lot', log('sqft_lot') )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["# find the correlation now\nhousing_df.stat.corr( 'price', 'sqft_lot' )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>0.0896608605871003\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["housing_df.stat.corr( 'log_price', 'log_sqft_lot' )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">13</span><span class=\"ansired\">]: </span>0.13772713692112706\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# calculating age of house\nfrom pyspark.sql.functions import lit\n\n# Lit is python function  \nhousing_df = housing_df.withColumn(\"age\", lit(2015) - col('yr_built'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["# find last rennovated age\nhousing_df = housing_df.withColumn(\"rennovate_age\", lit(2015) - col('yr_renovated'))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["# keep the copy of the original\nhousing_original_df = housing_df\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["continuous_features = ['sqft_living', 'bedrooms', 'bathrooms', 'floors',\n                    'log_sqft_lot', 'age', 'sqft_above',\n                    'sqft_living15', 'sqft_lot15', 'rennovate_age']\n\ncategorical_features = ['zipcode', 'waterfront',\n                      'grade', 'condition',\n                      'view']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["# Build datasets \ndef create_category_vars( dataset, field_name ):\n  idx_col = field_name + \"Index\"\n  col_vec = field_name + \"Vec\"\n\n  month_stringIndexer = StringIndexer( inputCol=field_name,\n                                       outputCol=idx_col )\n\n  month_model = month_stringIndexer.fit( dataset )\n  month_indexed = month_model.transform( dataset )\n\n  month_encoder = OneHotEncoder( dropLast=True,\n                                 inputCol=idx_col,\n                                 outputCol= col_vec )\n\n  return month_encoder.transform( month_indexed )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["# OneHot Encoding for all the categorical columns\n# Encoding - convert any text value within columns into the numbers Spark supply function - OneHotEncoder\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, PolynomialExpansion, VectorIndexer\n\nfor col in categorical_features:\n  housing_df = create_category_vars( housing_df, col )\n\nhousing_df.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">19</span><span class=\"ansired\">]: </span>DataFrame[id: bigint, date: string, price: decimal(7,0), bedrooms: int, bathrooms: double, sqft_living: int, sqft_lot: int, floors: double, waterfront: int, view: int, condition: int, grade: int, sqft_above: int, sqft_basement: int, yr_built: int, yr_renovated: int, zipcode: int, lat: double, long: double, sqft_living15: int, sqft_lot15: int, log_price: double, log_sqft_lot: double, age: int, rennovate_age: int, zipcodeIndex: double, zipcodeVec: vector, waterfrontIndex: double, waterfrontVec: vector, gradeIndex: double, gradeVec: vector, conditionIndex: double, conditionVec: vector, viewIndex: double, viewVec: vector]\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["# create features for vector Assembler\n# Continuous values = Cant be categoried like sq ft of house \nfeatureCols = continuous_features + ['zipcodeVec',\n                                   'waterfrontVec',\n                                   'gradeVec',\n                                   'conditionVec',\n                                   'viewVec']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["assembler = VectorAssembler( inputCols = featureCols, outputCol = \"features\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["housing_train_df = assembler.transform( housing_df )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["# Create label\nfrom pyspark.sql.functions import round\n\nhousing_train_df = housing_train_df.withColumn( \"label\", round('log_price', 4) )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["# split the dataset\ntrain_df, test_df = housing_train_df.randomSplit( [0.7, 0.3], seed = 30 )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["# build the linear regression model\nfrom pyspark.ml.regression import LinearRegression\n# regParam=0.0 \nlinreg = LinearRegression(maxIter=500, regParam=0.0)\nlm = linreg.fit( train_df )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"code","source":["# Where \nlm.intercept\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">26</span><span class=\"ansired\">]: </span>12.702546325066606\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["lm.coefficients\n\n# make predictions for test data and evaluate\ny_pred = lm.transform( test_df )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["y_pred.select( 'features', 'label', 'prediction' ).show( 5 )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-------+------------------+\n            features|  label|        prediction|\n+--------------------+-------+------------------+\n(99,[0,1,2,3,4,5,...|12.3673|12.235794187964384|\n(99,[0,1,2,3,4,5,...|12.3842|12.339364066296184|\n(99,[0,1,2,3,4,5,...|12.0725|12.251879708357627|\n(99,[0,1,2,3,4,5,...|13.6352| 13.52381225822129|\n(99,[0,1,2,3,4,5,...|13.5345|13.527023338760356|\n+--------------------+-------+------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["# calculate actual predicted price\nfrom pyspark.sql.functions import exp\n\ny_pred = y_pred.withColumn( \"y_pred\", exp( 'prediction' ) )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["# calculate RMSE\nfrom pyspark.ml.evaluation import RegressionEvaluator\nrmse_evaluator = RegressionEvaluator(labelCol=\"price\",\n                              predictionCol=\"y_pred\",\n                              metricName=\"rmse\" )\nlm_rmse = rmse_evaluator.evaluate( y_pred )\nlm_rmse"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">30</span><span class=\"ansired\">]: </span>178913.64762957647\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["# calcualte R-Squared - Diff between predicted value and actual value\nr2_evaluator = RegressionEvaluator(labelCol=\"price\",\n                              predictionCol=\"y_pred\",\n                              metricName=\"r2\" )\nlm_r2 = r2_evaluator.evaluate( y_pred )\nlm_r2"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">31</span><span class=\"ansired\">]: </span>0.7736320152018134\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["def get_r2_rmse( model, test_df ):\n  y_pred = model.transform( test_df )\n  y_pred = y_pred.withColumn( \"y_pred\", exp( 'prediction' ) )\n  rmse_evaluator = RegressionEvaluator(labelCol=\"price\",\n                              predictionCol=\"y_pred\",\n                              metricName=\"rmse\" )\n  r2_evaluator = RegressionEvaluator(labelCol=\"price\",\n                              predictionCol=\"y_pred\",\n                              metricName=\"r2\" )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["perf_params = get_r2_rmse( lm, test_df )\n\n# create dataframe to store all the model performances\n\nimport pandas as pd\n\nmodel_perf = pd.DataFrame( columns = ['name', 'rsquared', 'rmse'] )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["model_perf = model_perf.append( pd.Series( [\"Linear Regression\"] + perf_params ,\n                 index = model_perf.columns ),\n                 ignore_index = True )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-860385756073122&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> model_perf = model_perf.append( pd.Series( [&quot;Linear Regression&quot;] + perf_params ,\n</span><span class=\"ansigreen\">      2</span>                  index = model_perf.columns ),\n<span class=\"ansigreen\">      3</span>                  ignore_index = True )\n\n<span class=\"ansired\">TypeError</span>: can only concatenate list (not &quot;NoneType&quot;) to list</div>"]}}],"execution_count":34},{"cell_type":"code","source":["model_perf\n"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nlrModel = LinearRegression(maxIter=50)\n\n"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["paramGrid = ParamGridBuilder()                          \\\n  .addGrid(lrModel.regParam, [0.1, 0.01, 0.001])      \\\n  .addGrid(lrModel.elasticNetParam, [0.0])            \\\n  .build()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["evaluator = RegressionEvaluator(\n  metricName=\"r2\",\n  labelCol=\"label\",\n)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["crossval = CrossValidator(estimator=lrModel,\n                        estimatorParamMaps=paramGrid,\n                        evaluator=evaluator,\n                        numFolds=2)  # use 3+ folds in practice"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["cvModel = crossval.fit( train_df )\n"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["ridge_perf = get_r2_rmse( cvModel.bestModel, test_df )\n"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["model_perf = model_perf.append( pd.Series( [\"Ridge Regression\"] + ridge_perf ,\n                 index = model_perf.columns ),\n                 ignore_index = True )\n\nmodel_perf"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["#Using Lasso Regression  - Another method to avoid overfit \n# the regParam is a L1 (ridge) penalty, if elastic param is 1.0\nparamGrid = ParamGridBuilder()                          \\\n  .addGrid(lrModel.regParam, [0.1, 0.01, 0.001])      \\\n  .addGrid(lrModel.elasticNetParam, [1.0])            \\\n  .build()\n\nevaluator = RegressionEvaluator(\n  metricName=\"r2\",\n  labelCol=\"label\",\n)\n\ncrossval = CrossValidator(estimator=lrModel,\n                        estimatorParamMaps=paramGrid,\n                        evaluator=evaluator,\n                        numFolds=2)  # use 3+ folds in practice"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["cvModel = crossval.fit( train_df )\nlasso_perf = get_r2_rmse( cvModel.bestModel, test_df )\n"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["model_perf = model_perf.append( pd.Series( [\"Lasso Regression\"] + lasso_perf ,\n                 index = model_perf.columns ),\n                 ignore_index = True )\n\nmodel_perf"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":46}],"metadata":{"name":"HousePrice_LinearRegression","notebookId":677659841667552},"nbformat":4,"nbformat_minor":0}
